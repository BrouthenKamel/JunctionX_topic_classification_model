{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrouthenKamel/JunctionX_topic_classification_model/blob/main/JunctionX_topic_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing modules"
      ],
      "metadata": {
        "id": "7ksFv80Csbcc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A0_q5-P2PxjD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the dataset"
      ],
      "metadata": {
        "id": "M2tBCrVVsiGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_file = \"/content/education.txt\"\n",
        "entertainment_file = \"/content/entertainment.txt\"\n",
        "technology_file = \"/content/technology.txt\""
      ],
      "metadata": {
        "id": "QEA_AcymshHb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "names = [\"education\", \"entertainment\", \"technology\"]\n",
        "file_paths = [education_file, entertainment_file, technology_file]"
      ],
      "metadata": {
        "id": "lTJ1xOaLs1n8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = dict()\n",
        "\n",
        "for index, file_path in enumerate(file_paths):\n",
        "  with open(file_path, 'r') as f:\n",
        "      texts[names[index]] = f.readlines()"
      ],
      "metadata": {
        "id": "L5g_CxzYtF7E"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name in names:\n",
        "  texts[name] = [ text[:-2] for text in  texts[name]]"
      ],
      "metadata": {
        "id": "SSxH0hewtqOu"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = dict()\n",
        "\n",
        "columns[\"text\"] = []\n",
        "for name in names:\n",
        "  for text in texts[name]:\n",
        "    columns[\"text\"].append(text)"
      ],
      "metadata": {
        "id": "_8WZYJ6quYwY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns[\"education\"] = [1 for _ in range(len(texts[\"education\"]))] + [0 for _ in range(len(texts[\"entertainment\"]))] + [0 for _ in range(len(texts[\"technology\"]))]\n",
        "columns[\"entertainment\"] = [0 for _ in range(len(texts[\"education\"]))] + [1 for _ in range(len(texts[\"entertainment\"]))] + [0 for _ in range(len(texts[\"technology\"]))]\n",
        "columns[\"technology\"] = [0 for _ in range(len(texts[\"education\"]))] + [0 for _ in range(len(texts[\"entertainment\"]))] + [1 for _ in range(len(texts[\"technology\"]))]"
      ],
      "metadata": {
        "id": "JC73mcdUvUW8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCbQjsXbwejQ",
        "outputId": "e24465eb-fff1-4248-853b-0fafaead6c5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['text', 'education', 'entertainment', 'technology'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.DataFrame(columns, columns = columns.keys())"
      ],
      "metadata": {
        "id": "L3SS-6olwh6U"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.to_csv(\"/content/dataset.csv\")"
      ],
      "metadata": {
        "id": "39dzZr-1wpPp"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data cleaning"
      ],
      "metadata": {
        "id": "S48L-5mN1JC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "string.punctuation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5av6PxrW0v4A",
        "outputId": "17c3cdc3-cb4b-4796-f589-68a43a7b4eaf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punct(text):\n",
        "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
        "    return text.translate(translator)"
      ],
      "metadata": {
        "id": "SmOr1AMi1D7x"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['text'] = dataset[\"text\"].apply(remove_punct)"
      ],
      "metadata": {
        "id": "CDmiPOkq1F-V"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words(\"english\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYVdrbvr1T0O",
        "outputId": "150b435e-d8bf-4bd5-8e4d-6e9e45834524"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(text):\n",
        "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
        "    return \" \".join(filtered_words)"
      ],
      "metadata": {
        "id": "n-f4XS2m1eO9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['reduced_text'] = dataset[\"text\"].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "3D2uojYC1ftm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['reduced_text'] = dataset['reduced_text'].str.replace(r'[^a-zA-Z ]', '')"
      ],
      "metadata": {
        "id": "_5J33YKG16gg",
        "outputId": "e7d8e799-8906-4d34-9993-762873432b53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-bfab9e3ff640>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset['reduced_text'] = dataset['reduced_text'].str.replace(r'[^a-zA-Z ]', '')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary"
      ],
      "metadata": {
        "id": "QvxknYWP1_Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def counter_word(text_col):\n",
        "    count = Counter()\n",
        "    for text in text_col.values:\n",
        "        for word in text.split():\n",
        "            count[word] += 1\n",
        "    return count"
      ],
      "metadata": {
        "id": "BPmO7ZjY2CRg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = counter_word(dataset[\"reduced_text\"])\n",
        "print(len(counter))\n",
        "counter.most_common(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwt-DzF32FVd",
        "outputId": "a91d20dc-e6d5-44b4-b8f3-fe9645bb06b7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1474\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('education', 88),\n",
              " ('favorite', 71),\n",
              " ('technology', 64),\n",
              " ('learning', 57),\n",
              " ('used', 52)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting the dataset"
      ],
      "metadata": {
        "id": "n2naVGzQ2RjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = dataset[\"reduced_text\"]\n",
        "y = dataset.drop(columns = [\"text\", \"reduced_text\"])"
      ],
      "metadata": {
        "id": "PNazaMav2Usq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-multilearn"
      ],
      "metadata": {
        "id": "2jcXyCip2sNe",
        "outputId": "7b341959-0265-4f32-a9eb-453641c93ef7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skmultilearn.model_selection import iterative_train_test_split"
      ],
      "metadata": {
        "id": "rCgyPblq2ulT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test = iterative_train_test_split(x.values.reshape(-1,1), y.values, test_size = 0.2)"
      ],
      "metadata": {
        "id": "4sRY8X722zP6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_fractions = y_test.sum(axis=0) / y.sum(axis=0)\n",
        "print(y_fractions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "558nV2yE3FKi",
        "outputId": "c6b4b384-cbe8-487d-eab1-5f2c0dedabd7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "education        0.200772\n",
            "entertainment    0.200000\n",
            "technology       0.198697\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions & Evaluation metric"
      ],
      "metadata": {
        "id": "Mya1z35g3yA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(prediction_probas, threshold):\n",
        "  predictions = []\n",
        "\n",
        "  for probas in prediction_probas:\n",
        "    prediction = []\n",
        "    for proba in probas:\n",
        "      if proba > threshold:\n",
        "        prediction.append(1)\n",
        "      else:\n",
        "        prediction.append(0)\n",
        "    predictions.append(prediction)\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "mLJD5jqb33VW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metrics(y_test, predictions):\n",
        "  accuracies = dict()\n",
        "  recalls = dict()\n",
        "  precisions = dict()\n",
        "  f1_scores = dict()\n",
        "  for columns_index in range(y_test.shape[1]):\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    true_negatives = 0\n",
        "    false_negatives = 0\n",
        "    for data_point_index in range(y_test.shape[0]):\n",
        "      if(y_test[data_point_index][columns_index] == 1 and predictions[data_point_index][columns_index] == 1):\n",
        "        true_positives += 1\n",
        "      if(y_test[data_point_index][columns_index] == 0 and predictions[data_point_index][columns_index] == 0):\n",
        "        true_negatives += 1\n",
        "      if(y_test[data_point_index][columns_index] == 1 and predictions[data_point_index][columns_index] == 0):\n",
        "        false_negatives += 1\n",
        "      if(y_test[data_point_index][columns_index] == 0 and predictions[data_point_index][columns_index] == 1):\n",
        "        false_positives += 1\n",
        "    accuracies[y.columns[columns_index]] = (true_positives + true_negatives) / y_test.shape[0]\n",
        "    if (true_positives + false_negatives) == 0:\n",
        "      recalls[y.columns[columns_index]] = 0\n",
        "    else:\n",
        "      recalls[y.columns[columns_index]] = true_positives / (true_positives + false_negatives)\n",
        "    if (true_positives + false_positives) == 0:\n",
        "      precisions[y.columns[columns_index]] = 0\n",
        "    else:\n",
        "      precisions[y.columns[columns_index]] = true_positives / (true_positives + false_positives)\n",
        "    if ( recalls[y.columns[columns_index]] + precisions[y.columns[columns_index]] ) != 0:\n",
        "      f1_scores[y.columns[columns_index]] = 2 * ( recalls[y.columns[columns_index]] * precisions[y.columns[columns_index]] ) / ( recalls[y.columns[columns_index]] + precisions[y.columns[columns_index]] )\n",
        "    else:\n",
        "      f1_scores[y.columns[columns_index]] = 0\n",
        "  return accuracies, recalls, precisions, f1_scores"
      ],
      "metadata": {
        "id": "gQNEBtXk32Wn"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "MM1Nu4tD4I_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "ticrLPKl4Ice"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import transformers\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "model = transformers.TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=y.shape[1])"
      ],
      "metadata": {
        "id": "FQP9iNYE4TbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "learning_rate = 1e-4\n",
        "num_epochs = 20\n",
        "# callback_threshold = 0.1 // callbacks=[LossCallback(callback_threshold)]\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sDTeEVht4hiL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = x_train.flatten().tolist()\n",
        "train_labels = y_train\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels)).shuffle(len(train_labels)).batch(batch_size)"
      ],
      "metadata": {
        "id": "M6SN9Bq-4zzF"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8FnOABf47T8",
        "outputId": "13da41d1-16e0-42b8-b9ca-4169b626f9f5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "11/11 [==============================] - 49s 357ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "11/11 [==============================] - 3s 300ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "11/11 [==============================] - 3s 287ms/step - loss: 0.0089 - accuracy: 0.9985\n",
            "Epoch 4/20\n",
            "11/11 [==============================] - 3s 291ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "11/11 [==============================] - 4s 336ms/step - loss: 0.0210 - accuracy: 0.9954\n",
            "Epoch 6/20\n",
            "11/11 [==============================] - 3s 276ms/step - loss: 0.0204 - accuracy: 0.9938\n",
            "Epoch 7/20\n",
            "11/11 [==============================] - 3s 293ms/step - loss: 0.0093 - accuracy: 0.9985\n",
            "Epoch 8/20\n",
            "11/11 [==============================] - 3s 282ms/step - loss: 0.0084 - accuracy: 0.9985\n",
            "Epoch 9/20\n",
            "11/11 [==============================] - 3s 271ms/step - loss: 0.0110 - accuracy: 0.9969\n",
            "Epoch 10/20\n",
            "11/11 [==============================] - 3s 260ms/step - loss: 0.0310 - accuracy: 0.9892\n",
            "Epoch 11/20\n",
            "11/11 [==============================] - 3s 277ms/step - loss: 0.0114 - accuracy: 0.9969\n",
            "Epoch 12/20\n",
            "11/11 [==============================] - 3s 272ms/step - loss: 0.0261 - accuracy: 0.9938\n",
            "Epoch 13/20\n",
            "11/11 [==============================] - 4s 332ms/step - loss: 0.0084 - accuracy: 0.9985\n",
            "Epoch 14/20\n",
            "11/11 [==============================] - 3s 268ms/step - loss: 0.0211 - accuracy: 0.9938\n",
            "Epoch 15/20\n",
            "11/11 [==============================] - 3s 274ms/step - loss: 0.0436 - accuracy: 0.9877\n",
            "Epoch 16/20\n",
            "11/11 [==============================] - 3s 263ms/step - loss: 0.0256 - accuracy: 0.9938\n",
            "Epoch 17/20\n",
            "11/11 [==============================] - 3s 287ms/step - loss: 0.0468 - accuracy: 0.9892\n",
            "Epoch 18/20\n",
            "11/11 [==============================] - 3s 260ms/step - loss: 0.0692 - accuracy: 0.9769\n",
            "Epoch 19/20\n",
            "11/11 [==============================] - 3s 261ms/step - loss: 0.0313 - accuracy: 0.9923\n",
            "Epoch 20/20\n",
            "11/11 [==============================] - 3s 293ms/step - loss: 0.0292 - accuracy: 0.9938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd73c361ee0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = x_test.flatten().tolist()\n",
        "test_labels = y_test\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels)).batch(batch_size)\n",
        "test_outputs = model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "Hnp9F1DK6m7F",
        "outputId": "20d0e68a-a012-4bde-9b04-09f16695ee03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 3s 89ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_bool = tf.math.sigmoid(test_outputs.logits).numpy() > 0.5"
      ],
      "metadata": {
        "id": "IoStoZeh60NW"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "for prediction in predictions_bool:\n",
        "  predict = []\n",
        "  for bool in prediction:\n",
        "    predict.append(1) if bool else predict.append(0)\n",
        "  predictions.append(predict)"
      ],
      "metadata": {
        "id": "Ud1aAyEB7UiW"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies, recalls, precisions, f1_scores = metrics(y_test, predictions)"
      ],
      "metadata": {
        "id": "1GnnGG_w7zLi"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in y.columns:\n",
        "  print(f\"{column} : \\n--> accuracy = {accuracies[column]:.2f} // f1_scores = {f1_scores[column]:.2f} \\n---[ recall = {recalls[column]:.2f} \\n---[ precision = {precisions[column]:.2f} \\n\")"
      ],
      "metadata": {
        "id": "UwwJfQWb98iE",
        "outputId": "e0a3e403-5136-4977-eefd-da3631f88428",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "education : \n",
            "--> accuracy = 0.99 // f1_scores = 0.98 \n",
            "---[ recall = 1.00 \n",
            "---[ precision = 0.96 \n",
            "\n",
            "entertainment : \n",
            "--> accuracy = 0.99 // f1_scores = 0.99 \n",
            "---[ recall = 0.98 \n",
            "---[ precision = 1.00 \n",
            "\n",
            "technology : \n",
            "--> accuracy = 0.99 // f1_scores = 0.99 \n",
            "---[ recall = 0.98 \n",
            "---[ precision = 1.00 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/model\")\n",
        "tokenizer.save_pretrained(\"/content/tokenizer\")"
      ],
      "metadata": {
        "id": "eWGUORqd_xzy",
        "outputId": "d15bd2f9-9baf-4f42-9077-c987f1c978b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/tokenizer/tokenizer_config.json',\n",
              " '/content/tokenizer/special_tokens_map.json',\n",
              " '/content/tokenizer/vocab.txt',\n",
              " '/content/tokenizer/added_tokens.json',\n",
              " '/content/tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ]
}